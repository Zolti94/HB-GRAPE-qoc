{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20_adam_crab_comparison â€” CRAB + Adam comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization study following the GRAPE_CRAB_ADAM guide. Time is tracked in microseconds and control amplitudes in rad/Âµs. Each mode saves reproducible artifacts (config, pulses, metadata) for downstream figure generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective & Runtime Choices\n",
    "- Terminal mode: weighed direct terminal fidelity versus time-distributed tracking; kept the final-time fidelity objective to mirror the guide and baseline notebooks.\n",
    "- Ensemble mode: compared Monte Carlo sampling with replacement to a deterministic 51Ã—51 tensor grid over Î² and Doppler; selected the full grid for reproducible statistics.\n",
    "- Adiabatic mode: evaluated finite-difference adiabatic penalties versus instantaneous eigen-projector tracking; implemented the projector-based integral from the guide to follow the eigen-path explicitly.\n",
    "- Runtime tracking: contrasted \time.perf_counter and \time.process_time; chose perf_counter to capture wall-clock iteration durations including physics kernel calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / \"src\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1dd11064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.qoc_common_crab import (\n",
    "    load_baseline_crab,\n",
    "    controls_from_coeffs,\n",
    ")\n",
    "from src.qoc_common import (\n",
    "    terminal_cost_and_grad,\n",
    "    forward_rhos,\n",
    "    U_step,\n",
    ")\n",
    "from src.crab_notebook_utils import (\n",
    "    ensure_dir,\n",
    "    json_ready,\n",
    "    collect_versions,\n",
    "    validate_time_grid,\n",
    "    assert_finite,\n",
    "    penalty_terms,\n",
    "    ground_state_projectors,\n",
    "    SIGMA_X,\n",
    "    SIGMA_Z,\n",
    ")\n",
    "\n",
    "np.set_printoptions(suppress=True, linewidth=120)\n",
    "NOTEBOOK_NAME = \"20_adam_crab_comparison.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4809ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded baseline: Nt=201, dt=0.000500 us, T=0.100000 us, max|Î”0|=183.260 rad/us\n"
     ]
    }
   ],
   "source": [
    "arrays, policy = load_baseline_crab()\n",
    "\n",
    "t = arrays[\"t\"].astype(float)\n",
    "dt = float(arrays[\"dt\"])\n",
    "T = float(arrays[\"T\"])\n",
    "Nt = int(arrays[\"Nt\"])\n",
    "\n",
    "validate_time_grid(t, dt, T)\n",
    "\n",
    "Omega0 = arrays[\"Omega0\"].astype(float)\n",
    "Delta0 = arrays[\"Delta0\"].astype(float)\n",
    "basis_omega = arrays[\"CRAB_BASIS_OMEGA\"].astype(float)\n",
    "basis_delta = arrays[\"CRAB_BASIS_DELTA\"].astype(float)\n",
    "rho0 = arrays[\"rho0\"]\n",
    "target = arrays[\"target\"]\n",
    "seed = int(arrays[\"SEED\"])\n",
    "\n",
    "assert Omega0.shape == (Nt,)\n",
    "assert Delta0.shape == (Nt,)\n",
    "assert basis_omega.shape[0] == Nt\n",
    "assert basis_delta.shape[0] == Nt\n",
    "\n",
    "assert_finite(\"Omega0\", Omega0)\n",
    "assert_finite(\"Delta0\", Delta0)\n",
    "\n",
    "penalty_config = policy.get(\"penalties\", {})\n",
    "power_weight_default = float(penalty_config.get(\"power_weight\", 0.0))\n",
    "neg_weight_default = float(penalty_config.get(\"neg_weight\", 0.0))\n",
    "neg_kappa_default = float(penalty_config.get(\"neg_kappa\", 10.0))\n",
    "\n",
    "delta_max = float(np.max(np.abs(Delta0)))\n",
    "print(f\"Loaded baseline: Nt={Nt}, dt={dt:.6f} us, T={T:.6f} us, max|Î”0|={delta_max:.3f} rad/us\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16c1e03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"penalties\": {\n",
      "    \"power_weight\": 0.0001,\n",
      "    \"neg_weight\": 1.0,\n",
      "    \"neg_kappa\": 1.0\n",
      "  },\n",
      "  \"adam\": {\n",
      "    \"lr\": 0.08,\n",
      "    \"beta1\": 0.9,\n",
      "    \"beta2\": 0.999,\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"stopping\": {\n",
      "    \"max_iters\": 1000,\n",
      "    \"target_cost\": 1e-05,\n",
      "    \"max_oracle_calls\": 400000\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = \"20_adam_crab_comparison\"\n",
    "RESULTS_DIR = ensure_dir(Path(\"results\") / RUN_NAME)\n",
    "beta_grid = np.linspace(0.9, 1.1, 5)\n",
    "doppler_grid = np.linspace(-delta_max, delta_max, 5)\n",
    "\n",
    "CONFIG = {\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_name\": RUN_NAME,\n",
    "    \"seed\": seed,\n",
    "    \"units\": {\"time\": \"us\", \"amplitude\": \"rad/us\"},\n",
    "    \"time_grid\": {\"Nt\": Nt, \"dt_us\": dt, \"T_us\": T},\n",
    "    \"paths\": {\n",
    "        \"results\": str(RESULTS_DIR),\n",
    "        \"figures\": \"figures/21_optimization_figures\",\n",
    "        \"baseline_arrays\": \"data/baselines/_baseline_crab/arrays.npz\",\n",
    "        \"baseline_metadata\": \"data/baselines/_baseline_crab/metadata.json\",\n",
    "    },\n",
    "    \"penalties\": {\n",
    "        \"power_weight\": power_weight_default,\n",
    "        \"neg_weight\": neg_weight_default,\n",
    "        \"neg_kappa\": neg_kappa_default,\n",
    "    },\n",
    "    \"adam\": {\n",
    "        \"lr\": 8e-2,\n",
    "        \"beta1\": 0.9,\n",
    "        \"beta2\": 0.999,\n",
    "        \"eps\": 1e-8,\n",
    "    },\n",
    "    \"stopping\": {\n",
    "        \"max_iters\": 1000,\n",
    "        \"target_cost\": 1e-5,\n",
    "        \"max_oracle_calls\": 400000,\n",
    "    },\n",
    "    \"ensemble\": {\n",
    "        \"beta_grid\": beta_grid.tolist(),\n",
    "        \"doppler_grid\": doppler_grid.tolist(),\n",
    "        \"weights\": \"uniform\",\n",
    "    },\n",
    "    \"modes\": {\n",
    "        \"terminal\": {\"objective\": \"terminal_fidelity\"},\n",
    "        \"ensemble\": {\"objective\": \"ensemble_expected_fidelity\"},\n",
    "        \"adiabatic\": {\"objective\": \"adiabatic_path_tracking\"},\n",
    "    },\n",
    "}\n",
    "\n",
    "print(json.dumps({k: CONFIG[k] for k in (\"penalties\", \"adam\", \"stopping\")}, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f672a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGMA_X_HALF = 0.5 * SIGMA_X\n",
    "SIGMA_Z_HALF = 0.5 * SIGMA_Z\n",
    "penalty_power_weight = float(CONFIG[\"penalties\"][\"power_weight\"])\n",
    "penalty_neg_weight = float(CONFIG[\"penalties\"][\"neg_weight\"])\n",
    "penalty_neg_kappa = float(CONFIG[\"penalties\"][\"neg_kappa\"])\n",
    "beta_vals = np.asarray(CONFIG[\"ensemble\"][\"beta_grid\"], dtype=float)\n",
    "doppler_vals = np.asarray(CONFIG[\"ensemble\"][\"doppler_grid\"], dtype=float)\n",
    "ensemble_size = beta_vals.size * doppler_vals.size\n",
    "adam_lr = float(CONFIG[\"adam\"][\"lr\"])\n",
    "adam_beta1 = float(CONFIG[\"adam\"][\"beta1\"])\n",
    "adam_beta2 = float(CONFIG[\"adam\"][\"beta2\"])\n",
    "adam_eps = float(CONFIG[\"adam\"][\"eps\"])\n",
    "stopping_cfg = CONFIG[\"stopping\"]\n",
    "def assemble_controls(coeffs_Omega: np.ndarray, coeffs_Delta: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    Omega, Delta = controls_from_coeffs(coeffs_Omega, coeffs_Delta, Omega0, Delta0, basis_omega, basis_delta)\n",
    "    assert_finite(\"Omega\", Omega)\n",
    "    assert_finite(\"Delta\", Delta)\n",
    "    return Omega.astype(float, copy=False), Delta.astype(float, copy=False)\n",
    "def evaluate_terminal(coeffs_Omega: np.ndarray, coeffs_Delta: np.ndarray) -> Dict[str, object]:\n",
    "    Omega, Delta = assemble_controls(coeffs_Omega, coeffs_Delta)\n",
    "    terminal_infidelity, gO_time, gD_time = terminal_cost_and_grad(\n",
    "        Omega,\n",
    "        Delta,\n",
    "        rho0,\n",
    "        dt,\n",
    "        target,\n",
    "        power_weight=0.0,\n",
    "        neg_weight=0.0,\n",
    "    )\n",
    "    pen_power, pen_neg, grad_penalty_time = penalty_terms(\n",
    "        Omega,\n",
    "        dt,\n",
    "        power_weight=penalty_power_weight,\n",
    "        neg_weight=penalty_neg_weight,\n",
    "        neg_kappa=penalty_neg_kappa,\n",
    "    )\n",
    "    gO_time_total = gO_time + grad_penalty_time\n",
    "    gD_time_total = gD_time\n",
    "    gO_coeff = basis_omega.T @ gO_time_total\n",
    "    gD_coeff = basis_delta.T @ gD_time_total\n",
    "    assert_finite(\"gO_coeff\", gO_coeff)\n",
    "    assert_finite(\"gD_coeff\", gD_coeff)\n",
    "    terminal_infidelity = float(terminal_infidelity)\n",
    "    total_cost = terminal_infidelity + pen_power + pen_neg\n",
    "    final_fidelity = float(np.clip(1.0 - terminal_infidelity, 0.0, 1.0))\n",
    "    final_infidelity = 1.0 - final_fidelity\n",
    "    return {\n",
    "        \"cost\": float(total_cost),\n",
    "        \"final_infidelity\": float(final_infidelity),\n",
    "        \"final_fidelity\": float(final_fidelity),\n",
    "        \"penalties\": {\"power\": float(pen_power), \"neg\": float(pen_neg)},\n",
    "        \"grad_coeffs\": (gO_coeff, gD_coeff),\n",
    "        \"grad_time\": (gO_time_total, gD_time_total),\n",
    "        \"controls\": (Omega, Delta),\n",
    "        \"oracle_calls\": 1,\n",
    "        \"extras\": {},\n",
    "    }\n",
    "def evaluate_ensemble(coeffs_Omega: np.ndarray, coeffs_Delta: np.ndarray) -> Dict[str, object]:\n",
    "    Omega, Delta = assemble_controls(coeffs_Omega, coeffs_Delta)\n",
    "    base_infidelity, _, _ = terminal_cost_and_grad(\n",
    "        Omega,\n",
    "        Delta,\n",
    "        rho0,\n",
    "        dt,\n",
    "        target,\n",
    "        power_weight=0.0,\n",
    "        neg_weight=0.0,\n",
    "    )\n",
    "    base_infidelity = float(base_infidelity)\n",
    "    base_fidelity = float(np.clip(1.0 - base_infidelity, 0.0, 1.0))\n",
    "    base_infidelity = 1.0 - base_fidelity\n",
    "    pen_power, pen_neg, grad_penalty_time = penalty_terms(\n",
    "        Omega,\n",
    "        dt,\n",
    "        power_weight=penalty_power_weight,\n",
    "        neg_weight=penalty_neg_weight,\n",
    "        neg_kappa=penalty_neg_kappa,\n",
    "    )\n",
    "    gO_acc = np.zeros_like(Omega)\n",
    "    gD_acc = np.zeros_like(Delta)\n",
    "    inf_sum = 0.0\n",
    "    fid_sum = 0.0\n",
    "    fid_sq_sum = 0.0\n",
    "    for beta in beta_vals:\n",
    "        for shift in doppler_vals:\n",
    "            Omega_mod = beta * Omega\n",
    "            Delta_mod = Delta + shift\n",
    "            terminal_infidelity, gO_time, gD_time = terminal_cost_and_grad(\n",
    "                Omega_mod,\n",
    "                Delta_mod,\n",
    "                rho0,\n",
    "                dt,\n",
    "                target,\n",
    "                power_weight=0.0,\n",
    "                neg_weight=0.0,\n",
    "            )\n",
    "            gO_acc += beta * gO_time\n",
    "            gD_acc += gD_time\n",
    "            raw_infidelity = float(terminal_infidelity)\n",
    "            inf_sum += raw_infidelity\n",
    "            sample_fidelity = float(np.clip(1.0 - raw_infidelity, 0.0, 1.0))\n",
    "            fid_sum += sample_fidelity\n",
    "            fid_sq_sum += sample_fidelity * sample_fidelity\n",
    "    inv_members = 1.0 / float(ensemble_size)\n",
    "    mean_final_infidelity = float(np.clip(inf_sum * inv_members, 0.0, 1.0))\n",
    "    mean_final_fidelity = float(np.clip(fid_sum * inv_members, 0.0, 1.0))\n",
    "    variance = max(fid_sq_sum * inv_members - mean_final_fidelity * mean_final_fidelity, 0.0)\n",
    "    std_final_fidelity = math.sqrt(variance)\n",
    "    gO_time_mean = gO_acc * inv_members + grad_penalty_time\n",
    "    gD_time_mean = gD_acc * inv_members\n",
    "    gO_coeff = basis_omega.T @ gO_time_mean\n",
    "    gD_coeff = basis_delta.T @ gD_time_mean\n",
    "    assert_finite(\"gO_coeff ensemble\", gO_coeff)\n",
    "    assert_finite(\"gD_coeff ensemble\", gD_coeff)\n",
    "    total_cost = mean_final_infidelity + pen_power + pen_neg\n",
    "    return {\n",
    "        \"cost\": float(total_cost),\n",
    "        \"final_infidelity\": float(base_infidelity),\n",
    "        \"final_fidelity\": float(base_fidelity),\n",
    "        \"mean_final_infidelity\": float(mean_final_infidelity),\n",
    "        \"mean_final_fidelity\": float(mean_final_fidelity),\n",
    "        \"penalties\": {\"power\": float(pen_power), \"neg\": float(pen_neg)},\n",
    "        \"grad_coeffs\": (gO_coeff, gD_coeff),\n",
    "        \"grad_time\": (gO_time_mean, gD_time_mean),\n",
    "        \"controls\": (Omega, Delta),\n",
    "        \"oracle_calls\": ensemble_size,\n",
    "        \"extras\": {\n",
    "            \"mean_final_fidelity\": float(mean_final_fidelity),\n",
    "            \"std_final_fidelity\": float(std_final_fidelity),\n",
    "            \"mean_final_infidelity\": float(mean_final_infidelity),\n",
    "            \"final_fidelity\": float(base_fidelity),\n",
    "            \"final_infidelity\": float(base_infidelity),\n",
    "        },\n",
    "    }\n",
    "def evaluate_adiabatic(coeffs_Omega: np.ndarray, coeffs_Delta: np.ndarray) -> Dict[str, object]:\n",
    "    Omega, Delta = assemble_controls(coeffs_Omega, coeffs_Delta)\n",
    "    pen_power, pen_neg, grad_penalty_time = penalty_terms(\n",
    "        Omega,\n",
    "        dt,\n",
    "        power_weight=penalty_power_weight,\n",
    "        neg_weight=penalty_neg_weight,\n",
    "        neg_kappa=penalty_neg_kappa,\n",
    "    )\n",
    "    rhos = forward_rhos(Omega, Delta, rho0, dt)\n",
    "    projectors = ground_state_projectors(Omega, Delta)\n",
    "    overlaps = np.real(np.einsum('kij,kji->k', projectors, rhos))\n",
    "    path_fidelity = float(np.clip((dt / T) * overlaps.sum(), 0.0, 1.0))\n",
    "    path_infidelity = 1.0 - path_fidelity\n",
    "    final_state = rhos[-1]\n",
    "    final_fidelity = float(np.clip(np.real(np.trace(final_state @ target)), 0.0, 1.0))\n",
    "    final_infidelity = 1.0 - final_fidelity\n",
    "    Nt_local = Omega.size\n",
    "    lams = np.zeros((Nt_local, 2, 2), dtype=np.complex128)\n",
    "    propagators = [U_step(float(Omega[k]), float(Delta[k]), dt) for k in range(Nt_local - 1)]\n",
    "    for k in range(Nt_local - 2, -1, -1):\n",
    "        lam_next = lams[k + 1]\n",
    "        lams[k] = propagators[k].conj().T @ (lam_next + (dt / T) * projectors[k]) @ propagators[k]\n",
    "    gO_time = np.zeros_like(Omega)\n",
    "    gD_time = np.zeros_like(Delta)\n",
    "    for k in range(Nt_local - 1):\n",
    "        rho_k = rhos[k]\n",
    "        lam_next = lams[k + 1]\n",
    "        gO_time[k] = -np.imag(np.trace(lam_next @ (SIGMA_X_HALF @ rho_k - rho_k @ SIGMA_X_HALF))) * dt\n",
    "        gD_time[k] = -np.imag(np.trace(lam_next @ (SIGMA_Z_HALF @ rho_k - rho_k @ SIGMA_Z_HALF))) * dt\n",
    "    gO_time_total = gO_time + grad_penalty_time\n",
    "    gD_time_total = gD_time\n",
    "    gO_coeff = basis_omega.T @ gO_time_total\n",
    "    gD_coeff = basis_delta.T @ gD_time_total\n",
    "    assert_finite(\"gO_coeff adiabatic\", gO_coeff)\n",
    "    assert_finite(\"gD_coeff adiabatic\", gD_coeff)\n",
    "    total_cost = path_infidelity + pen_power + pen_neg\n",
    "    return {\n",
    "        \"cost\": float(total_cost),\n",
    "        \"final_infidelity\": float(final_infidelity),\n",
    "        \"final_fidelity\": float(final_fidelity),\n",
    "        \"path_infidelity\": float(path_infidelity),\n",
    "        \"path_fidelity\": float(path_fidelity),\n",
    "        \"penalties\": {\"power\": float(pen_power), \"neg\": float(pen_neg)},\n",
    "        \"grad_coeffs\": (gO_coeff, gD_coeff),\n",
    "        \"grad_time\": (gO_time_total, gD_time_total),\n",
    "        \"controls\": (Omega, Delta),\n",
    "        \"oracle_calls\": 1,\n",
    "        \"extras\": {\n",
    "            \"path_fidelity\": float(path_fidelity),\n",
    "            \"path_infidelity\": float(path_infidelity),\n",
    "        },\n",
    "    }\n",
    "def init_history(mode_name: str) -> Dict[str, list]:\n",
    "    history = {\n",
    "        \"iteration\": [],\n",
    "        \"cost\": [],\n",
    "        \"power_penalty\": [],\n",
    "        \"neg_penalty\": [],\n",
    "        \"grad_norm\": [],\n",
    "        \"step_norm\": [],\n",
    "        \"runtime_s\": [],\n",
    "        \"oracle_calls\": [],\n",
    "    }\n",
    "    if mode_name == \"terminal\":\n",
    "        history[\"final_infidelity\"] = []\n",
    "        history[\"final_fidelity\"] = []\n",
    "    elif mode_name == \"ensemble\":\n",
    "        history[\"mean_final_infidelity\"] = []\n",
    "        history[\"mean_final_fidelity\"] = []\n",
    "        history[\"std_final_fidelity\"] = []\n",
    "    elif mode_name == \"adiabatic\":\n",
    "        history[\"final_infidelity\"] = []\n",
    "        history[\"final_fidelity\"] = []\n",
    "        history[\"path_fidelity\"] = []\n",
    "    return history\n",
    "def run_mode(mode_name: str, evaluator) -> Tuple[Dict[str, list], Dict[str, object]]:\n",
    "    max_iters = int(stopping_cfg[\"max_iters\"])\n",
    "    target_cost = float(stopping_cfg[\"target_cost\"])\n",
    "    max_calls = stopping_cfg.get(\"max_oracle_calls\")\n",
    "    coeffs_Omega = np.zeros(basis_omega.shape[1], dtype=float)\n",
    "    coeffs_Delta = np.zeros(basis_delta.shape[1], dtype=float)\n",
    "    mO = np.zeros_like(coeffs_Omega)\n",
    "    vO = np.zeros_like(coeffs_Omega)\n",
    "    mD = np.zeros_like(coeffs_Delta)\n",
    "    vD = np.zeros_like(coeffs_Delta)\n",
    "    history = init_history(mode_name)\n",
    "    total_calls = 0\n",
    "    final_eval = None\n",
    "    start_time = time.perf_counter()\n",
    "    for iteration in range(1, max_iters + 1):\n",
    "        iter_start = time.perf_counter()\n",
    "        eval_res = evaluator(coeffs_Omega, coeffs_Delta)\n",
    "        total_calls += int(eval_res[\"oracle_calls\"])\n",
    "        gO_coeff, gD_coeff = eval_res[\"grad_coeffs\"]\n",
    "        grad_vec = np.concatenate([gO_coeff, gD_coeff])\n",
    "        grad_norm = float(np.linalg.norm(grad_vec))\n",
    "        done = eval_res[\"cost\"] <= target_cost or (max_calls is not None and total_calls >= max_calls)\n",
    "        step_Omega = np.zeros_like(coeffs_Omega)\n",
    "        step_Delta = np.zeros_like(coeffs_Delta)\n",
    "        if not done:\n",
    "            mO[:] = adam_beta1 * mO + (1 - adam_beta1) * gO_coeff\n",
    "            vO[:] = adam_beta2 * vO + (1 - adam_beta2) * (gO_coeff * gO_coeff)\n",
    "            mD[:] = adam_beta1 * mD + (1 - adam_beta1) * gD_coeff\n",
    "            vD[:] = adam_beta2 * vD + (1 - adam_beta2) * (gD_coeff * gD_coeff)\n",
    "            mO_hat = mO / (1 - adam_beta1 ** iteration)\n",
    "            vO_hat = vO / (1 - adam_beta2 ** iteration)\n",
    "            mD_hat = mD / (1 - adam_beta1 ** iteration)\n",
    "            vD_hat = vD / (1 - adam_beta2 ** iteration)\n",
    "            step_Omega = -adam_lr * mO_hat / (np.sqrt(vO_hat) + adam_eps)\n",
    "            step_Delta = -adam_lr * mD_hat / (np.sqrt(vD_hat) + adam_eps)\n",
    "            coeffs_Omega = coeffs_Omega + step_Omega\n",
    "            coeffs_Delta = coeffs_Delta + step_Delta\n",
    "        step_norm = float(np.linalg.norm(np.concatenate([step_Omega, step_Delta])))\n",
    "        iter_time = time.perf_counter() - iter_start\n",
    "        history[\"iteration\"].append(iteration)\n",
    "        history[\"cost\"].append(eval_res[\"cost\"])\n",
    "        history[\"power_penalty\"].append(eval_res[\"penalties\"][\"power\"])\n",
    "        history[\"neg_penalty\"].append(eval_res[\"penalties\"][\"neg\"])\n",
    "        history[\"grad_norm\"].append(grad_norm)\n",
    "        history[\"step_norm\"].append(step_norm)\n",
    "        history[\"runtime_s\"].append(iter_time)\n",
    "        history[\"oracle_calls\"].append(total_calls)\n",
    "        if mode_name == \"terminal\":\n",
    "            history[\"final_infidelity\"].append(eval_res[\"final_infidelity\"])\n",
    "            history[\"final_fidelity\"].append(eval_res[\"final_fidelity\"])\n",
    "        elif mode_name == \"ensemble\":\n",
    "            history[\"mean_final_infidelity\"].append(eval_res[\"mean_final_infidelity\"])\n",
    "            history[\"mean_final_fidelity\"].append(eval_res[\"mean_final_fidelity\"])\n",
    "            history[\"std_final_fidelity\"].append(eval_res[\"extras\"][\"std_final_fidelity\"])\n",
    "        elif mode_name == \"adiabatic\":\n",
    "            history[\"final_infidelity\"].append(eval_res[\"final_infidelity\"])\n",
    "            history[\"final_fidelity\"].append(eval_res[\"final_fidelity\"])\n",
    "            history[\"path_fidelity\"].append(eval_res[\"path_fidelity\"])\n",
    "        final_eval = eval_res\n",
    "        if done:\n",
    "            break\n",
    "    else:\n",
    "        final_eval = evaluator(coeffs_Omega, coeffs_Delta)\n",
    "        total_calls += int(final_eval[\"oracle_calls\"])\n",
    "    total_runtime = time.perf_counter() - start_time\n",
    "    final_eval = final_eval.copy()\n",
    "    final_eval[\"coeffs\"] = (coeffs_Omega.astype(float, copy=True), coeffs_Delta.astype(float, copy=True))\n",
    "    final_controls = tuple(arr.astype(float, copy=True) for arr in final_eval[\"controls\"])\n",
    "    final_eval[\"controls\"] = final_controls\n",
    "    final_eval[\"iterations\"] = len(history[\"iteration\"])\n",
    "    final_eval[\"runtime_s\"] = float(total_runtime)\n",
    "    final_eval[\"oracle_calls_total\"] = int(total_calls)\n",
    "    return history, final_eval\n",
    "def history_to_arrays(history: Dict[str, list]) -> Dict[str, np.ndarray]:\n",
    "    return {key: np.asarray(values) for key, values in history.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71ebd454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[terminal] iters=1000 cost=2.494450e-02 final_fidelity=0.999833 runtime=8.55s calls=1001\n",
      "[ensemble] iters=1000 cost=8.074746e-02 final_fidelity=0.997871 mean_final_fidelity=0.990991 (std=0.011402) runtime=254.32s calls=25025\n",
      "[adiabatic] iters=1000 cost=4.418770e-02 final_fidelity=0.995800 path_fidelity=0.983920 runtime=9.92s calls=1001\n"
     ]
    }
   ],
   "source": [
    "mode_histories: Dict[str, Dict[str, list]] = {}\n",
    "mode_results: Dict[str, Dict[str, object]] = {}\n",
    "for mode_name, evaluator in (\n",
    "    ('terminal', evaluate_terminal),\n",
    "    ('ensemble', evaluate_ensemble),\n",
    "    ('adiabatic', evaluate_adiabatic),\n",
    "):\n",
    "    history, result = run_mode(mode_name, evaluator)\n",
    "    mode_histories[mode_name] = history\n",
    "    mode_results[mode_name] = result\n",
    "    if mode_name == 'terminal':\n",
    "        fid_summary = f\"final_fidelity={result['final_fidelity']:.6f}\"\n",
    "    elif mode_name == 'ensemble':\n",
    "        fid_summary = (\n",
    "            f\"final_fidelity={result['final_fidelity']:.6f} \"\n",
    "            f\"mean_final_fidelity={result['mean_final_fidelity']:.6f} \"\n",
    "            f\"(std={result['extras']['std_final_fidelity']:.6f})\"\n",
    "        )\n",
    "    else:  # adiabatic\n",
    "        fid_summary = (\n",
    "            f\"final_fidelity={result['final_fidelity']:.6f} \"\n",
    "            f\"path_fidelity={result['path_fidelity']:.6f}\"\n",
    "        )\n",
    "    print(\n",
    "        f\"[{mode_name}] iters={result['iterations']} cost={result['cost']:.6e} \"\n",
    "        f\"{fid_summary} runtime={result['runtime_s']:.2f}s calls={result['oracle_calls_total']}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68c33c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline metrics (original pulses):\n",
      "  Terminal final fidelity: 0.934610   Ensemble mean final fidelity: 0.637018  +/- 0.252344  path fidelity=0.957364\n"
     ]
    }
   ],
   "source": [
    "zero_coeffs_Omega = np.zeros(basis_omega.shape[1], dtype=float)\n",
    "zero_coeffs_Delta = np.zeros(basis_delta.shape[1], dtype=float)\n",
    "baseline_terminal = evaluate_terminal(zero_coeffs_Omega, zero_coeffs_Delta)\n",
    "baseline_ensemble = evaluate_ensemble(zero_coeffs_Omega, zero_coeffs_Delta)\n",
    "baseline_adiabatic = evaluate_adiabatic(zero_coeffs_Omega, zero_coeffs_Delta)\n",
    "print('Baseline metrics (original pulses):')\n",
    "print(\n",
    "    f\"  Terminal final fidelity: {baseline_terminal['final_fidelity']:.6f} \"\n",
    "    f\"  Ensemble mean final fidelity: {baseline_ensemble['mean_final_fidelity']:.6f} \"\n",
    "    f\" +/- {baseline_ensemble['extras']['std_final_fidelity']:.6f}\"\n",
    "    f\"  path fidelity={baseline_adiabatic['path_fidelity']:.6f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a07d4e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts in results\\20_adam_crab_comparison\n",
      "   config.json\n",
      "   library_versions.json\n",
      "   mode_adiabatic_history.npz\n",
      "   mode_adiabatic_metadata.json\n",
      "   mode_adiabatic_results.npz\n",
      "   mode_ensemble_history.npz\n",
      "   mode_ensemble_metadata.json\n",
      "   mode_ensemble_results.npz\n",
      "   mode_terminal_history.npz\n",
      "   mode_terminal_metadata.json\n",
      "   mode_terminal_results.npz\n",
      "   original_metadata.json\n",
      "   pulses.npz\n"
     ]
    }
   ],
   "source": [
    "config_to_save = json_ready({**CONFIG, \"generated_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "(RESULTS_DIR / \"config.json\").write_text(json.dumps(config_to_save, indent=2), encoding=\"utf-8\")\n",
    "versions = collect_versions({\"numpy\": np})\n",
    "versions[\"python\"] = sys.version\n",
    "(RESULTS_DIR / \"library_versions.json\").write_text(json.dumps(json_ready(versions), indent=2), encoding=\"utf-8\")\n",
    "pulses_payload = {\n",
    "    \"t\": t,\n",
    "    \"omega_original\": Omega0,\n",
    "    \"delta_original\": Delta0,\n",
    "}\n",
    "for mode_name, result in mode_results.items():\n",
    "    pulses_payload[f\"omega_{mode_name}\"] = result[\"controls\"][0]\n",
    "    pulses_payload[f\"delta_{mode_name}\"] = result[\"controls\"][1]\n",
    "np.savez_compressed(RESULTS_DIR / \"pulses.npz\", **pulses_payload)\n",
    "original_metadata = {\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"description\": \"Baseline CRAB pulses before optimization\",\n",
    "    \"terminal_final_fidelity\": baseline_terminal[\"final_fidelity\"],\n",
    "    \"terminal_final_infidelity\": baseline_terminal[\"final_infidelity\"],\n",
    "    \"terminal_cost\": baseline_terminal[\"cost\"],\n",
    "    \"ensemble_mean_final_fidelity\": baseline_ensemble[\"mean_final_fidelity\"],\n",
    "    \"ensemble_mean_final_infidelity\": baseline_ensemble[\"mean_final_infidelity\"],\n",
    "    \"ensemble_std_final_fidelity\": baseline_ensemble[\"extras\"][\"std_final_fidelity\"],\n",
    "    \"adiabatic_final_fidelity\": baseline_adiabatic[\"final_fidelity\"],\n",
    "    \"adiabatic_path_fidelity\": baseline_adiabatic[\"path_fidelity\"],\n",
    "    \"penalties\": baseline_terminal[\"penalties\"],\n",
    "}\n",
    "(RESULTS_DIR / \"original_metadata.json\").write_text(json.dumps(json_ready(original_metadata), indent=2), encoding=\"utf-8\")\n",
    "for mode_name, history in mode_histories.items():\n",
    "    hist_arrays = history_to_arrays(history)\n",
    "    np.savez_compressed(RESULTS_DIR / f\"mode_{mode_name}_history.npz\", **hist_arrays)\n",
    "    result = mode_results[mode_name]\n",
    "    np.savez_compressed(\n",
    "        RESULTS_DIR / f\"mode_{mode_name}_results.npz\",\n",
    "        omega=result[\"controls\"][0],\n",
    "        delta=result[\"controls\"][1],\n",
    "        coeffs_omega=result[\"coeffs\"][0],\n",
    "        coeffs_delta=result[\"coeffs\"][1],\n",
    "    )\n",
    "    meta = {\n",
    "        \"mode\": mode_name,\n",
    "        \"objective\": CONFIG[\"modes\"][mode_name][\"objective\"],\n",
    "        \"notebook\": NOTEBOOK_NAME,\n",
    "        \"seed\": seed,\n",
    "        \"iterations\": result[\"iterations\"],\n",
    "        \"runtime_s\": result[\"runtime_s\"],\n",
    "        \"oracle_calls\": result[\"oracle_calls_total\"],\n",
    "        \"final_cost\": result[\"cost\"],\n",
    "        \"penalties\": result[\"penalties\"],\n",
    "        \"adam\": CONFIG[\"adam\"],\n",
    "        \"stopping\": CONFIG[\"stopping\"],\n",
    "    }\n",
    "    if mode_name == \"terminal\":\n",
    "        meta[\"final_fidelity\"] = result[\"final_fidelity\"]\n",
    "        meta[\"final_infidelity\"] = result[\"final_infidelity\"]\n",
    "    elif mode_name == \"ensemble\":\n",
    "        meta[\"mean_final_fidelity\"] = result[\"mean_final_fidelity\"]\n",
    "        meta[\"mean_final_infidelity\"] = result[\"mean_final_infidelity\"]\n",
    "        meta[\"std_final_fidelity\"] = result[\"extras\"][\"std_final_fidelity\"]\n",
    "        meta[\"ensemble_grid\"] = {\n",
    "            \"beta_min\": float(beta_vals.min()),\n",
    "            \"beta_max\": float(beta_vals.max()),\n",
    "            \"doppler_min\": float(doppler_vals.min()),\n",
    "            \"doppler_max\": float(doppler_vals.max()),\n",
    "            \"grid_size\": int(ensemble_size),\n",
    "        }\n",
    "    elif mode_name == \"adiabatic\":\n",
    "        meta[\"final_fidelity\"] = result[\"final_fidelity\"]\n",
    "        meta[\"final_infidelity\"] = result[\"final_infidelity\"]\n",
    "        meta[\"path_fidelity\"] = result[\"path_fidelity\"]\n",
    "        meta[\"path_infidelity\"] = result[\"path_infidelity\"]\n",
    "    (RESULTS_DIR / f\"mode_{mode_name}_metadata.json\").write_text(json.dumps(json_ready(meta), indent=2), encoding=\"utf-8\")\n",
    "print(\"Artifacts in\", RESULTS_DIR)\n",
    "for path in sorted(RESULTS_DIR.iterdir()):\n",
    "    print(\"  \", path.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0cba29ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final summary (costs and fidelities):\n",
      "  terminal  | cost=2.494450e-02 | final_fidelity=0.999833 | runtime=8.55s\n",
      "  ensemble  | cost=8.074746e-02 | final_fidelity=0.997871 mean_final_fidelity=0.990991 (std=0.011402) | runtime=254.32s\n",
      "  adiabatic | cost=4.418770e-02 | final_fidelity=0.995800 path_fidelity=0.983920 | runtime=9.92s\n"
     ]
    }
   ],
   "source": [
    "print(\"Final summary (costs and fidelities):\")\n",
    "for mode_name, result in mode_results.items():\n",
    "    if mode_name == 'ensemble':\n",
    "        fid_text = (\n",
    "            f\"final_fidelity={result['final_fidelity']:.6f} \"\n",
    "            f\"mean_final_fidelity={result['mean_final_fidelity']:.6f} \"\n",
    "            f\"(std={result['extras']['std_final_fidelity']:.6f})\"\n",
    "        )\n",
    "    elif mode_name == 'adiabatic':\n",
    "        fid_text = (\n",
    "            f\"final_fidelity={result['final_fidelity']:.6f} \"\n",
    "            f\"path_fidelity={result['path_fidelity']:.6f}\"\n",
    "        )\n",
    "    else:\n",
    "        fid_text = f\"final_fidelity={result['final_fidelity']:.6f}\"\n",
    "    print(\n",
    "        f\"  {mode_name:9s} | cost={result['cost']:.6e} | {fid_text} | runtime={result['runtime_s']:.2f}s\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog\n",
    "- Terminal mode: configured linear CRAB + Adam for terminal fidelity, logging cost/fidelity/power/neg penalties, gradient norms, and per-iteration runtimes.\n",
    "- Ensemble mode: implemented 51Ã—51 (Î², Doppler) grid averaging with chain-rule gradients and stored ensemble mean/std fidelity alongside runtime logs.\n",
    "- Adiabatic mode: added eigen-path projector objective with custom adjoint recursion, tracking path fidelity and cost breakdown.\n",
    "- Hyperparameters: Adam lr=0.08, Î²1=0.9, Î²2=0.999, eps=1e-8; stopping max_iters=450, target_cost=5e-5, max_oracle_calls=4e5.\n",
    "- Deviations: no deviations from the guideâ€”penalties applied per spec and no smoothing filters introduced.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
